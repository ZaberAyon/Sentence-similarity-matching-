{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0528 21:45:07.712351  1112 __init__.py:56] Some hub symbols are not available because TensorFlow version is less than 1.14\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.layers import Dense, Input, LSTM, Dropout, Bidirectional, Lambda\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0528 21:47:32.493178  1112 deprecation.py:323] From c:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\tensorflow\\python\\ops\\control_flow_ops.py:3632: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "url = \"https://tfhub.dev/google/universal-sentence-encoder-large/3\"\n",
    "embed = hub.Module(url)\n",
    "\n",
    "\n",
    "def UniversalEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0529 01:16:15.442366  1112 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0529 01:16:16.885584  1112 saver.py:1483] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_20 (InputLayer)           (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 512)          0           input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 512)          0           input_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 256)          131328      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 256)          131328      lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_5 (RepeatVector)  (None, 3, 256)       0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_6 (RepeatVector)  (None, 3, 256)       0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_8 (Bidirectional) (None, 256)          394240      repeat_vector_5[0][0]            \n",
      "                                                                 repeat_vector_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 512)          0           bidirectional_8[0][0]            \n",
      "                                                                 bidirectional_8[1][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 128)          65664       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128)          512         dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 128)          0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            129         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 725,249\n",
      "Trainable params: 723,969\n",
      "Non-trainable params: 1,280\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout, RepeatVector, TimeDistributed\n",
    "\n",
    "input_text1 = Input(shape=(1,), dtype=tf.string)\n",
    "embedding1 = Lambda(UniversalEmbedding, output_shape=(512,))(input_text1)\n",
    "dense1 = Dense(256, activation='relu')(embedding1)\n",
    "\n",
    "\n",
    "input_text2 = Input(shape=(1,), dtype=tf.string)\n",
    "embedding2 = Lambda(UniversalEmbedding, output_shape=(512,))(input_text2)\n",
    "dense2 = Dense(256, activation='relu')(embedding2)\n",
    "\n",
    "net1 = RepeatVector(3)(dense1)\n",
    "net2 = RepeatVector(3)(dense2)\n",
    "\n",
    "lstm_layer = Bidirectional(LSTM(128, dropout=0.2, recurrent_dropout=.25))\n",
    "\n",
    "x1 = lstm_layer(net1)\n",
    "x2 = lstm_layer(net2)\n",
    "\n",
    "merged = concatenate([x1, x2])\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(0.25)(merged)\n",
    "merged = Dense(128, activation='relu')(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "merged = Dropout(0.25)(merged)\n",
    "preds = Dense(1, activation='sigmoid')(merged)\n",
    "\n",
    "model = Model(inputs=[input_text1, input_text2], outputs=preds)\n",
    "model.compile(loss='binary_crossentropy', optimizer='nadam', metrics=['acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
